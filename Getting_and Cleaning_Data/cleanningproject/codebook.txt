==================================================================
This is the code book for the tidy dataset generated from:
==================================================================
Human Activity Recognition Using Smartphones Dataset Version 1.0
==================================================================
Jorge L. Reyes-Ortiz, Davide Anguita, Alessandro Ghio, Luca Oneto.
Smartlab - Non Linear Complex Systems Laboratory
DITEN - Universit√† degli Studi di Genova.
Via Opera Pia 11A, I-16145, Genoa, Italy.
activityrecognition@smartlab.ws
www.smartlab.ws
==================================================================

The experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. Each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, we captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. The experiments have been video-recorded to label the data manually. The obtained dataset has been randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data. 

The sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window). The sensor acceleration signal, which has gravitational and body motion components, was separated using a Butterworth low-pass filter into body acceleration and gravity. The gravitational force is assumed to have only low frequency components, therefore a filter with 0.3 Hz cutoff frequency was used. From each window, a vector of features was obtained by calculating variables from the time and frequency domain.

Notes: 
======
- Features are normalized and bounded within [-1,1].

For each record in the tidy dataset the folowing variables are reported:
===============================================================================
DATA_TYPE: 	takes either the value "test" or "train" indicating if the observation corresponds to the test or 				train group
ACTIVITY:	indicates the activity being performed (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, 			STANDING, LAYING)
SUBJECT_ID: gives the identification number of the subject performing the test, takes values from 1 to 30
PARAMETER:	indicates the parameter being measured. See details underneath
			BodyAcc         
			BodyAccJerk     
			BodyGyro        
			BodyGyroJerk    
			GravityAcc      
			BodyBodyAccJerk
AXIS: 		indicates the axis corresponding to the observation parameter (x, y, z, mag). mag indicates the 			magnitude calculated using the ecuclidean norm.
DOMAIN:		indicates if the measurement belongs to either the time or frequency domain
MEAN_VALUE:	gives the mean value of the measured parameter
STANDARD_DEVIATION: gives the standard deviation of the measured parameter

PARAMETER details
=================

The features selected for this database come from the accelerometer and gyroscope 3-axial raw signals Acc-XYZ and Gyro-XYZ. These time domain signals were captured at a constant rate of 50 Hz. Then they were filtered using a median filter and a 3rd order low pass Butterworth filter with a corner frequency of 20 Hz to remove noise. Similarly, the acceleration signal was then separated into body and gravity acceleration signals (BodyAcc-XYZ and GravityAcc-XYZ) using another low pass Butterworth filter with a corner frequency of 0.3 Hz. 

Subsequently, the body linear acceleration and angular velocity were derived in time to obtain Jerk signals (BodyAccJerk-XYZ and BodyGyroJerk-XYZ). Also the magnitude of these three-dimensional signals were calculated using the Euclidean norm (BodyAcc-mag, GravityAcc-mag, BodyAccJerk-mag, BodyGyro-mag, BodyGyroJerk-mag). 

Finally a Fast Fourier Transform (FFT) was applied to some of these signals producing frequency domain signals for BodyAcc-XYZ, BodyAccJerk-XYZ, BodyGyro-XYZ, BodyAccJerk-mag, BodyGyro-mag, BodyGyroJerk-mag.

These signals were used to estimate variables of the feature vector for each pattern:  
'-XYZ' is used to denote 3-axial signals in the X, Y and Z directions and '-mag' to denote the magnitude
